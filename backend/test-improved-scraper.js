/**
 * Test Script for Improved LinkedIn Scraper
 * Tests the enhanced scraping system with database validation and authentication
 */

const LinkedInScraper = require('./services/linkedin-scraper');
const DatabaseValidationService = require('./services/database-validation');
const { query } = require('./utils/database');
const { v4: uuidv4 } = require('uuid');
const fs = require('fs').promises;
const path = require('path');

async function testImprovedScraper() {
  console.log('üöÄ Testing Improved LinkedIn Scraper with Enhanced Anti-Detection & Concurrency Control');
  console.log('=' .repeat(80));

  // Load real cookies from the provided JSON file
  const cookiesPath = 'C:\\Users\\krush\\OneDrive\\Desktop\\Final\\linkedin-automation-saas\\sd.json';
  let cookies = [];
  
  try {
    const cookiesData = await fs.readFile(cookiesPath, 'utf8');
    cookies = JSON.parse(cookiesData);
    console.log(`‚úÖ Loaded ${cookies.length} cookies from ${cookiesPath}`);
    
    // Check for authentication cookie
    const authCookie = cookies.find(cookie => cookie.name === 'li_at');
    if (authCookie) {
      console.log('üîê Authentication cookie (li_at) found');
    } else {
      console.log('‚ö†Ô∏è No authentication cookie (li_at) found');
    }
  } catch (error) {
    console.error('‚ùå Failed to load cookies:', error.message);
    return;
  }

  // Create scraper instance with enhanced settings and concurrency control
  const scraper = new LinkedInScraper({
    headless: false, // Keep visible for debugging
    timeout: 120000, // 2 minutes
    navigationTimeout: 180000, // 3 minutes  
    waitTimeout: 60000, // 1 minute
    retryAttempts: 3, // Try up to 3 times
    retryDelay: 5000, // 5 second base delay
    maxConcurrency: 3 // Limit to 3 concurrent operations
  });

  const mockAccount = {
    account_name: 'test-account',
    cookies: cookies
  };

  try {
    await scraper.initialize();
    console.log('‚úÖ Scraper initialized successfully');

    // Test cases for sequential execution
    const testCases = [
      {
        name: 'Bill Gates Profile',
        url: 'https://www.linkedin.com/in/williamhgates/',
        type: 'profile'
      },
      {
        name: 'Jeff Weiner Profile', 
        url: 'https://www.linkedin.com/in/jeffweiner08/',
        type: 'profile'
      },
      {
        name: 'Microsoft Company',
        url: 'https://www.linkedin.com/company/microsoft/',
        type: 'company'
      }
    ];

    console.log('\nüîÑ Testing Sequential Scraping (Original Method)');
    console.log('=' .repeat(60));

    for (const testCase of testCases) {
      console.log(`\n${'='.repeat(50)}`);
      console.log(`üß™ Testing: ${testCase.name}`);
      console.log(`üîó URL: ${testCase.url}`);
      console.log(`üìã Type: ${testCase.type}`);
      console.log(`${'='.repeat(50)}`);

      try {
        let result;
        const startTime = Date.now();

        if (testCase.type === 'profile') {
          result = await scraper.scrapeProfile(testCase.url, mockAccount);
        } else {
          result = await scraper.scrapeCompany(testCase.url, mockAccount);
        }

        const duration = ((Date.now() - startTime) / 1000).toFixed(2);
        
        console.log(`\nüìä Results for ${testCase.name}:`);
        console.log(`‚è±Ô∏è Duration: ${duration}s`);
        console.log(`‚úÖ Success: ${result.success || result.status === 'success'}`);
        console.log(`üîÑ Attempts: ${result.attempt || result.attempts_made || 'N/A'}`);
        console.log(`üìÑ Status: ${result.status}`);
        console.log(`üîç Content Validation: ${result.data?.content_validation || result.validation_status || 'N/A'}`);
        
        if (result.data) {
          if (testCase.type === 'profile') {
            console.log(`üë§ Name: ${result.data.full_name || 'Not found'}`);
            console.log(`üíº Title: ${result.data.headline || 'Not found'}`);
            console.log(`üìç Location: ${result.data.location || 'Not found'}`);
          } else {
            console.log(`üè¢ Company: ${result.data.company_name || 'Not found'}`);
            console.log(`üè≠ Industry: ${result.data.industry || 'Not found'}`);
            console.log(`üìç Location: ${result.data.location || 'Not found'}`);
          }
        }
        
        if (result.error) {
          console.log(`‚ùå Error: ${result.error}`);
        }
        
        if (result.html_file) {
          console.log(`üíæ HTML saved: ${result.html_file}`);
        }

      } catch (error) {
        console.error(`‚ùå Test failed for ${testCase.name}:`, error.message);
        console.error(`üîç Error type: ${error.constructor.name}`);
        
        if (error.message.includes('timeout')) {
          console.log('‚ö†Ô∏è This appears to be a timeout issue - the enhanced retry logic should help');
        }
      }
    }

    // Test batch processing with concurrency control
    console.log('\n\nüöÄ Testing Batch Processing with Concurrency Control');
    console.log('=' .repeat(60));
    
    const profileUrls = [
      'https://www.linkedin.com/in/williamhgates/',
      'https://www.linkedin.com/in/jeffweiner08/',
      'https://www.linkedin.com/in/satyanadella/'
    ];

    const companyUrls = [
      'https://www.linkedin.com/company/microsoft/',
      'https://www.linkedin.com/company/linkedin/'
    ];

    try {
      console.log('\nüì¶ Testing Profile Batch Processing...');
      const batchStartTime = Date.now();
      const profileResults = await scraper.scrapeBatch(profileUrls, mockAccount, 'profile');
      const batchDuration = ((Date.now() - batchStartTime) / 1000).toFixed(2);
      
      console.log(`\nüìä Profile Batch Results:`);
      console.log(`‚è±Ô∏è Total Duration: ${batchDuration}s`);
      console.log(`‚úÖ Successful: ${profileResults.filter(r => r.success).length}/${profileResults.length}`);
      
      profileResults.forEach((result, index) => {
        if (result.success) {
          console.log(`  ‚úÖ ${index + 1}. ${result.result.data?.full_name || 'Unknown'} - ${result.result.status}`);
        } else {
          console.log(`  ‚ùå ${index + 1}. ${result.url} - ${result.error}`);
        }
      });

      console.log('\nüì¶ Testing Company Batch Processing...');
      const companyBatchStartTime = Date.now();
      const companyResults = await scraper.scrapeBatch(companyUrls, mockAccount, 'company');
      const companyBatchDuration = ((Date.now() - companyBatchStartTime) / 1000).toFixed(2);
      
      console.log(`\nüìä Company Batch Results:`);
      console.log(`‚è±Ô∏è Total Duration: ${companyBatchDuration}s`);
      console.log(`‚úÖ Successful: ${companyResults.filter(r => r.success).length}/${companyResults.length}`);
      
      companyResults.forEach((result, index) => {
        if (result.success) {
          console.log(`  ‚úÖ ${index + 1}. ${result.result.data?.company_name || 'Unknown'} - ${result.result.status}`);
        } else {
          console.log(`  ‚ùå ${index + 1}. ${result.url} - ${result.error}`);
        }
      });

    } catch (error) {
      console.error('‚ùå Batch processing failed:', error.message);
    }

  } catch (error) {
    console.error('‚ùå Failed to initialize scraper:', error.message);
  } finally {
    try {
      await scraper.close();
      console.log('\n‚úÖ Scraper closed successfully');
      
      // Show final browser stats
      const stats = LinkedInScraper.getBrowserStats();
      console.log(`üìä Final Browser Stats: Instance=${stats.hasInstance}, RefCount=${stats.refCount}`);
      
    } catch (error) {
      console.error('‚ùå Error closing scraper:', error.message);
    }
  }

  console.log('\nüèÅ Enhanced Anti-Detection & Concurrency Testing Complete!');
  console.log('üìà Improvements implemented:');
  console.log('  ‚Ä¢ Extended timeouts (2-3 minutes)');
  console.log('  ‚Ä¢ Puppeteer-extra with stealth plugin');
  console.log('  ‚Ä¢ Randomized User-Agents and viewport sizes');
  console.log('  ‚Ä¢ Enhanced cookie management with domain context');
  console.log('  ‚Ä¢ Human-like actions (scrolling, mouse movements, reading simulation)');
  console.log('  ‚Ä¢ Comprehensive retry logic with exponential backoff');
  console.log('  ‚Ä¢ Enhanced browser arguments for anti-detection');
  console.log('  ‚Ä¢ Random delays throughout the process');
  console.log('  ‚Ä¢ Concurrency control (max 3 simultaneous operations)');
  console.log('  ‚Ä¢ Batch processing with Promise.allSettled');
  console.log('  ‚Ä¢ Singleton browser pattern for resource efficiency');

}

// Run the test
testImprovedScraper().catch(console.error);

/**
 * Enhanced LinkedIn Scraper Test with Improved Resource Management
 * Tests the scraper with singleton browser pattern and proper cleanup
 */

class ScrapingSystemTest {
  constructor() {
    this.scraper = null;
    this.testResults = [];
  }

  async initialize() {
    console.log('üöÄ Initializing LinkedIn Scraper Test System...');
    
    this.scraper = new LinkedInScraper({
      headless: false, // Set to false for debugging
      timeout: 90000 // 90 seconds timeout
    });
    
    await this.scraper.initialize();
    console.log('‚úÖ Scraper initialized successfully');
  }

  async testDatabaseValidation() {
    console.log('\nüìä Testing Database Validation Service...');
    
    try {
      // Test 1: Validate non-existent job
      console.log('Test 1: Validating non-existent job...');
      const fakeJobId = uuidv4();
      const jobExists = await DatabaseValidationService.validateJobExists(fakeJobId, 'scraping_jobs');
      console.log(`Result: ${jobExists ? '‚ùå FAIL' : '‚úÖ PASS'} - Non-existent job correctly identified`);
      
      // Test 2: Create a test scraping job
      console.log('Test 2: Creating test scraping job...');
      const testJobId = uuidv4();
      const testUserId = 'test-user-' + Date.now();
      
      // First create a test user if needed
      try {
        await query(`
          INSERT IGNORE INTO users (id, email, name, created_at, updated_at) 
          VALUES (?, ?, ?, NOW(), NOW())
        `, [testUserId, 'test@example.com', 'Test User']);
      } catch (e) {
        console.log('User may already exist, continuing...');
      }
      
      // Create test scraping job
      await query(`
        INSERT INTO scraping_jobs (id, user_id, job_name, job_type, status, created_at, updated_at)
        VALUES (?, ?, ?, ?, 'running', NOW(), NOW())
      `, [testJobId, testUserId, 'Test Scraping Job', 'profile_scraping']);
      
      console.log('‚úÖ Test scraping job created successfully');
      
      // Test 3: Validate the created job
      console.log('Test 3: Validating created job...');
      const createdJobExists = await DatabaseValidationService.validateJobExists(testJobId, 'scraping_jobs');
      console.log(`Result: ${createdJobExists ? '‚úÖ PASS' : '‚ùå FAIL'} - Created job validation`);
      
      // Test 4: Test safe profile insert
      console.log('Test 4: Testing safe profile insert...');
      const testProfileData = {
        url: 'https://www.linkedin.com/in/test-profile',
        full_name: 'Test User Profile',
        first_name: 'Test',
        last_name: 'User',
        headline: 'Software Engineer at Test Company',
        about: 'This is a test profile for validation purposes.',
        country: 'United States',
        city: 'San Francisco',
        industry: 'Technology',
        email: 'test.profile@example.com',
        current_job_title: 'Software Engineer',
        current_company: 'Test Company',
        skills: ['JavaScript', 'Node.js', 'React'],
        education: [{'school': 'Test University', 'degree': 'Computer Science'}],
        experience: [{'company': 'Test Company', 'title': 'Software Engineer'}],
        content_validation: 'valid'
      };
      
      const profileResultId = await DatabaseValidationService.safeInsertProfileResult(
        testProfileData,
        testJobId,
        { user_id: testUserId, job_name: 'Test Job', job_type: 'profile_scraping' }
      );
      
      console.log(`‚úÖ Profile result inserted with ID: ${profileResultId}`);
      
      // Test 5: Test safe company insert
      console.log('Test 5: Testing safe company insert...');
      const testCompanyData = {
        url: 'https://www.linkedin.com/company/test-company',
        name: 'Test Company Inc.',
        industry: 'Technology',
        location: 'San Francisco, CA',
        follower_count: '10000',
        company_size: '100-500 employees',
        website: 'https://testcompany.com',
        description: 'A test company for validation purposes.',
        content_validation: 'valid'
      };
      
      const companyResultId = await DatabaseValidationService.safeInsertCompanyResult(
        testCompanyData,
        testJobId,
        { user_id: testUserId, job_name: 'Test Job', job_type: 'company_scraping' }
      );
      
      console.log(`‚úÖ Company result inserted with ID: ${companyResultId}`);
      
      // Cleanup test data
      console.log('üßπ Cleaning up test data...');
      await query('DELETE FROM profile_results WHERE job_id = ?', [testJobId]);
      await query('DELETE FROM company_results WHERE job_id = ?', [testJobId]);
      await query('DELETE FROM scraping_jobs WHERE id = ?', [testJobId]);
      await query('DELETE FROM users WHERE id = ?', [testUserId]);
      
      console.log('‚úÖ Database validation tests completed successfully');
      return true;
      
    } catch (error) {
      console.error('‚ùå Database validation test failed:', error);
      return false;
    }
  }

  async testScrapingWithValidation() {
    console.log('\nüîç Testing Scraping with Content Validation...');
    
    try {
      // Load real cookies from the provided file
      const fs = require('fs');
      const path = require('path');
      const cookiesPath = 'C:\\Users\\krush\\OneDrive\\Desktop\\Final\\linkedin-automation-saas\\sd.json';
      
      let cookiesData = null;
      try {
        const cookiesContent = fs.readFileSync(cookiesPath, 'utf8');
        cookiesData = JSON.parse(cookiesContent);
        console.log(`‚úÖ Loaded ${cookiesData.length} cookies from ${cookiesPath}`);
      } catch (error) {
        console.warn(`‚ö†Ô∏è Could not load cookies from ${cookiesPath}:`, error.message);
      }
      
      // Test URLs (using public profiles that should be accessible)
      const testUrls = [
        'https://www.linkedin.com/in/williamhgates', // Bill Gates - public profile
        'https://www.linkedin.com/in/jeffweiner08', // Jeff Weiner - public profile
        'https://www.linkedin.com/company/microsoft' // Microsoft company page
      ];
      
      for (const url of testUrls) {
        console.log(`\nüåê Testing URL: ${url}`);
        
        try {
          let result;
          // Create account object with real cookies
          const mockAccount = {
            id: 'test-account',
            account_name: 'Test Account with Real Cookies',
            cookies: cookiesData ? JSON.stringify(cookiesData) : null
          };
          
          if (url.includes('/company/')) {
            result = await this.scraper.scrapeCompany(url, mockAccount);
          } else {
            result = await this.scraper.scrapeProfile(url, mockAccount);
          }
          
          console.log('üìä Scraping Result:');
          console.log(`- Success: ${result.success}`);
          console.log(`- Content Validation: ${result.content_validation}`);
          console.log(`- Validation Status: ${result.validation_status}`);
          
          if (result.success) {
            console.log(`- Name: ${result.name || result.fullName || 'N/A'}`);
            console.log(`- Title/Industry: ${result.title || result.headline || result.industry || 'N/A'}`);
            console.log(`- Location: ${result.location || 'N/A'}`);
          } else {
            console.log(`- Error: ${result.error}`);
          }
          
          this.testResults.push({
            url,
            success: result.success,
            validation: result.content_validation,
            error: result.error
          });
          
        } catch (error) {
          console.error(`‚ùå Error scraping ${url}:`, error.message);
          this.testResults.push({
            url,
            success: false,
            validation: 'error',
            error: error.message
          });
        }
        
        // Wait between requests to be respectful
        await new Promise(resolve => setTimeout(resolve, 3000));
      }
      
      return true;
      
    } catch (error) {
      console.error('‚ùå Scraping test failed:', error);
      return false;
    }
  }

  async generateTestReport() {
    console.log('\nüìã Test Report Summary');
    console.log('=' .repeat(50));
    
    const successCount = this.testResults.filter(r => r.success).length;
    const totalTests = this.testResults.length;
    
    console.log(`Total Tests: ${totalTests}`);
    console.log(`Successful: ${successCount}`);
    console.log(`Failed: ${totalTests - successCount}`);
    console.log(`Success Rate: ${((successCount / totalTests) * 100).toFixed(1)}%`);
    
    console.log('\nDetailed Results:');
    this.testResults.forEach((result, index) => {
      console.log(`${index + 1}. ${result.url}`);
      console.log(`   Status: ${result.success ? '‚úÖ SUCCESS' : '‚ùå FAILED'}`);
      console.log(`   Validation: ${result.validation}`);
      if (result.error) {
        console.log(`   Error: ${result.error}`);
      }
      console.log('');
    });
  }

  async cleanup() {
    if (this.scraper && this.scraper.browser) {
      await this.scraper.browser.close();
      console.log('üßπ Browser closed');
    }
  }

  async runFullTest() {
    try {
      await this.initialize();
      
      // Test database validation
      const dbTestSuccess = await this.testDatabaseValidation();
      
      // Test scraping with validation
      const scrapingTestSuccess = await this.testScrapingWithValidation();
      
      // Generate report
      await this.generateTestReport();
      
      console.log('\nüéØ Overall Test Result:');
      if (dbTestSuccess && scrapingTestSuccess) {
        console.log('‚úÖ All tests completed successfully!');
      } else {
        console.log('‚ùå Some tests failed. Please review the results above.');
      }
      
    } catch (error) {
      console.error('‚ùå Test execution failed:', error);
    } finally {
      await this.cleanup();
    }
  }
}

// Run the test if this file is executed directly
if (require.main === module) {
  const test = new ScrapingSystemTest();
  test.runFullTest().catch(console.error);
}

module.exports = ScrapingSystemTest;