version: '3.8'

services:
  # PostgreSQL Database (updated from MySQL for better JSON support)
  postgres:
    image: postgres:15-alpine
    container_name: linkedin-automation-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DATABASE:-linkedin_automation}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/database/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
      - ./backend/database/migrations:/docker-entrypoint-initdb.d/migrations
    networks:
      - linkedin-automation-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for BullMQ job queue
  redis:
    image: redis:7-alpine
    container_name: linkedin-automation-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - linkedin-automation-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: linkedin-automation-backend
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DATABASE:-linkedin_automation}
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - JWT_EXPIRES_IN=${JWT_EXPIRES_IN:-24h}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - FRONTEND_URL=http://localhost:3000
      - CHROME_HEADLESS=true
      - CHROME_USER_DATA_DIR=/app/tmp/chrome-data
      - WORKER_CONCURRENCY=${WORKER_CONCURRENCY:-2}
      - WORKER_TIMEOUT=${WORKER_TIMEOUT:-300000}
      - UPLOAD_DIR=/app/uploads
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-52428800}
      - MAX_FILES=${MAX_FILES:-5}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - linkedin-automation-network
    volumes:
      - ./backend/logs:/app/logs
      - backend_uploads:/app/uploads
      - chrome_data:/app/tmp/chrome-data
    healthcheck:
      test: ["CMD", "node", "healthcheck.js"]
      interval: 30s
      timeout: 10s
      retries: 3

  # BullMQ Worker (separate container for job processing)
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: linkedin-automation-worker
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DATABASE:-linkedin_automation}
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - CHROME_HEADLESS=true
      - CHROME_USER_DATA_DIR=/app/tmp/chrome-data
      - WORKER_CONCURRENCY=${WORKER_CONCURRENCY:-2}
      - WORKER_TIMEOUT=${WORKER_TIMEOUT:-300000}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - linkedin-automation-network
    volumes:
      - ./backend/logs:/app/logs
      - backend_uploads:/app/uploads
      - chrome_data:/app/tmp/chrome-data
    command: ["node", "workers/worker.js"]

  # Frontend Dashboard
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: linkedin-automation-frontend
    restart: unless-stopped
    ports:
      - "3000:80"
    environment:
      - REACT_APP_API_URL=http://localhost:5000
    depends_on:
      - backend
    networks:
      - linkedin-automation-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  backend_uploads:
    driver: local
  chrome_data:
    driver: local

networks:
  linkedin-automation-network:
    driver: bridge